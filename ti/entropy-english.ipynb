{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Entropia do Inglês\n",
    "\n",
    "Vamos aproximar a entropia do Inglês. Para tanto iremos utilizar o texto Ulysses de James Joyce. Quanto maior o texto (ou conjunto de textos), melhor será nossa aproximação. \n",
    "\n",
    "Vamos inicialmente baixar o texto do Projeto Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "wget -q http://www.gutenberg.org/files/4300/4300-0.txt -O /tmp/ulysses.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Podemos facilmente verificar o número de linhas e caracteres desse texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  33185 1586393 /tmp/ulysses.txt\n"
     ]
    }
   ],
   "source": [
    "wc -lc /tmp/ulysses.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Vamos ver um trecho desse texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stately, plump Buck Mulligan came from the stairhead, bearing a bowl of\n",
      "lather on which a mirror and a razor lay crossed. A yellow\n",
      "dressinggown, ungirdled, was sustained gently behind him on the mild\n",
      "morning air. He held the bowl aloft and intoned:\n",
      "\n",
      "—_Introibo ad altare Dei_.\n",
      "\n",
      "Halted, he peered down the dark winding stairs and called out coarsely:\n",
      "\r"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tail -c 361"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Inicialmente, iremos assumir que a fonte produz uma sequência de caracteres e que esta sequência é i.i.d. (independente e identicamente distribuída). É uma suposição errônea, como veremos adiante, mas simplifica o problema. Além disso, para simplificar, iremos supor que letras maiúsculas e minúsculas são equivalentes.\n",
    "\n",
    "Usando esta última suposição, vamos transformar as maiúsculas em minúsculas. \n",
    "\n",
    "Veremos os resultados inicialmente apenas nesse trecho visualizado acima e depois obteremos o resultado para todo o texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stately, plump buck mulligan came from the stairhead, bearing a bowl of\n",
      "lather on which a mirror and a razor lay crossed. a yellow\n",
      "dressinggown, ungirdled, was sustained gently behind him on the mild\n",
      "morning air. he held the bowl aloft and intoned:\n",
      "\n",
      "—_introibo ad altare dei_.\n",
      "\n",
      "halted, he peered down the dark winding stairs and called out coarsely:\n",
      "\r"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tail -c 361 | tr 'A-Z' 'a-z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Vamos agora fazer mais uma simplificação: desconsiderar os caracteres diferentes de [a-z]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statelyplumpbuckmulligancamefromthestairheadbearingabowloflatheronwhichamirrorandarazorlaycrossedayellowdressinggownungirdledwassustainedgentlybehindhimonthemildmorningairheheldthebowlaloftandintonedintroiboadaltaredeihaltedhepeereddownthedarkwindingstairsandcalledoutcoarsely"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tail -c 361 | tr 'A-Z' 'a-z' | tr -dc 'a-z' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Precisamos agora contabilizar quantas vezes cada caractere apareceu. Para tanto vamos dispor cada caractere em uma linha, depois ordená-los e contar. \n",
    "\n",
    "Para melhor visualização, vamos exibir as 10 primeiras linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "t\n",
      "a\n",
      "t\n",
      "e\n",
      "l\n",
      "y\n",
      "p\n",
      "l\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tail -c 361 | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Em seguida vamos ordenar alfabéticamente. \n",
    "\n",
    "Vamos ilustrar a ordenação sobre essa 10 linhas primeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "e\n",
      "e\n",
      "h\n",
      "j\n",
      "o\n",
      "p\n",
      "r\n",
      "t\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | head | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "E agora o resultado da ordenação sobre todos o trecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tc\te\te\ti\tl\to\tr\ts\tt\n",
      "a\tc\te\te\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\te\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n",
      "a\tc\te\tf\ti\tl\to\tr\ts\tu\n"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | sort | column -c 80 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "E agora vamos contabilizar as ocorrências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     55 a\t      9 f\t      7 k\t      9 p\t      4 v\n",
      "     19 b\t     24 g\t     34 l\t     47 r\t     17 w\n",
      "     26 c\t     29 h\t     14 m\t     47 s\t     21 y\n",
      "     35 d\t     47 i\t     44 n\t     60 t\t      1 z\n",
      "     90 e\t      9 j\t     62 o\t     26 u\n"
     ]
    }
   ],
   "source": [
    "head -c 1250 /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | sort | uniq -ic | column -c 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Por vim, vamos verificar o número de ocorrência dos caracteres em todo o texto. Vamos aproveitar e numerar as linhas do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t  94117 a\t    10\t   2414 j\t    19\t  77671 s\n",
      "     2\t  21433 b\t    11\t  12203 k\t    20\t 101741 t\n",
      "     3\t  30507 c\t    12\t  55540 l\t    21\t  33764 u\n",
      "     4\t  49606 d\t    13\t  31891 m\t    22\t   9870 v\n",
      "     5\t 143271 e\t    14\t  81154 n\t    23\t  26453 w\n",
      "     6\t  27010 f\t    15\t  92726 o\t    24\t   1466 x\n",
      "     7\t  28220 g\t    16\t  22859 p\t    25\t  24597 y\n",
      "     8\t  73078 h\t    17\t   1342 q\t    26\t   1076 z\n",
      "     9\t  82481 i\t    18\t  71037 r\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | sort | uniq -ic | nl | column -c 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Vamos salvar o resultado em um arquivo chamado *chars.txt* e utilizá-lo para fazer um histograma utilizando o *gnuplot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z' | \\\n",
    "sed 's/\\(.\\)/\\1\\n/g' | sort | uniq -ic | nl > chars.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat chars.txt | gnuplot -e \"set terminal png; set output 'imgs/ulysses.png'; set style fill solid; set boxwidth 1; set title 'Ulysses'; plot '-' using 1:2:xtic(3) with boxes notitle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "![histograma caracteres](imgs/ulysses.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Para calcular a entropia, vamos baixar a função *entropy* da biblioteca *clscripts*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "wget -q https://raw.githubusercontent.com/leolca/clscripts/master/entropy.m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Vamos exibir o código da função de Octave para calcular a entropia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function H = entropy(p,b)\n",
      "\n",
      "  if (nargin == 0 || nargin > 2) print_usage (); endif;\n",
      "  if any(p < 0) | any(p > 1) | abs(sum(p)-1) > 1E-10, error('not a valid pmf!'); endif;\n",
      "\n",
      "  id = find(p!=0);\n",
      "  p = p(id);\n",
      "  H = sum( - p .* log2(p) );\n",
      "\n",
      "  if nargin > 1, H *= log(2)/log(b); endif;\n",
      "\n",
      "endfunction\n"
     ]
    }
   ],
   "source": [
    "tail -n 23 entropy.m | head -n 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Iremos necessitar apenas da segunda coluna do arquivo *chars.txt* que salvamos anteriormente. Vamos salvar esta segunda coluna em um arquivo chamado *chars.counts*, que será carregado dentro do Octave para calculármos a entropia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat chars.txt | awk '{print $2}' > chars.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "No Octave, vamos usar a estimativa de máxima verossimilhança para obtermos as probabilidades e assim utilizar a função *entropy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "octave"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2057 bits\n",
      "4.2057 bits\n"
     ]
    }
   ],
   "source": [
    "c = load('chars.counts');\n",
    "p = c./sum(c); % mle\n",
    "H = entropy(p);\n",
    "printf('%d bits',H);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "octave"
   },
   "source": [
    "## Palavras\n",
    "\n",
    "Vamos agora considerar que as palavras sejam os símbolos produzidos pela fonte. Vamos novamente aproximar a entropia e comparar a entropia por caractere com o resultado anterior.\n",
    "\n",
    "Ao refazer o exemplo anterior, vamos seguir as mesmas simplificações: converter maiúsculas em minúsculas e remover os caracteres diferentes de [a-z ]. Vamos manter o espaço pois este será o caracter de separação entre palavras.\n",
    "\n",
    "Exibimos abaixo apenas as primeiras palavras mais frequentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t  12382 the\t    18\t   1293 is\t    35\t    711 had\n",
      "     2\t   7315 of\t    19\t   1273 him\t    36\t    604 like\n",
      "     3\t   6154 and\t    20\t   1132 by\t    37\t    598 what\n",
      "     4\t   5615 a\t    21\t   1131 at\t    38\t    593 have\n",
      "     5\t   4483 to\t    22\t   1122 all\t    39\t    592 one\n",
      "     6\t   4375 in\t    23\t   1039 as\t    40\t    580 but\n",
      "     7\t   3182 he\t    24\t    956 she\t    41\t    566 their\n",
      "     8\t   2824 his\t    25\t    942 from\t    42\t    555 there\n",
      "     9\t   2270 i\t    26\t    938 said\t    43\t    550 an\n",
      "    10\t   2186 that\t    27\t    911 or\t    44\t    549 them\n",
      "    11\t   2182 with\t    28\t    819 they\t    45\t    547 no\n",
      "    12\t   2026 it\t    29\t    801 be\t    46\t    540 mr\n",
      "    13\t   1884 on\t    30\t    789 not\t    47\t    523 bloom\n",
      "    14\t   1816 was\t    31\t    785 me\t    48\t    505 so\n",
      "    15\t   1690 for\t    32\t    771 out\t    49\t    493 if\n",
      "    16\t   1638 you\t    33\t    723 up\t    50\t    489 then\n",
      "    17\t   1534 her\t    34\t    714 my\n",
      "nl: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "cat /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z ' | tr -s ' ' | tr ' ' '\\n' | \\\n",
    "sort | uniq -c | sort -rn | nl | head -n 50 | column -c 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Vamos salvar o resultado geral em um arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat /tmp/ulysses.txt | tr 'A-Z' 'a-z' | tr -dc 'a-z ' | tr -s ' ' | tr ' ' '\\n' | \\\n",
    "sort | uniq -c | sort -rn | nl > words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "E vamos utilizar esses dados para fazer um gráfico log-log da frequência de ocorrência das palavras versus raque das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat words.txt | gnuplot -e \"set terminal png; set output 'imgs/ulysses-words.png'; set xlabel 'rank'; set logscale xy; set title 'loglog freq. of words'; plot '-' using 1:2 with lines notitle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "![zipf ulysses](imgs/ulysses-words.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Esta relação quase linear (quando observado em um gráfico log-log) é conhecida como lei de Zipf.\n",
    "\n",
    "Leia sobre ela em: https://en.wikipedia.org/wiki/Zipf%27s_law\n",
    "\n",
    "\n",
    "Até agora temos o número de ocorrência das palavras, o que nos permite aproximar a entropia por palavra. Para aproximar a entropia por caractere, devemos calcular o comprimento esperado das palavras. Precisamos então contabilizar o comprimento de cada palavra. Esta tarefa pode ser realizada fácilmente com o awk. Vamos imprimir os dados anteriores e também o comprimento da palavras (3a coluna)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat words.txt | awk 'BEGIN {OFS = \"\\t\"} {print $1, $2, length($3), $3}' > wordslen.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Para carregar os dados no Octave, vamos manter apenas o números do resultado anterior, ou seja, vamos suprimir a 3a coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "cat words.txt | awk 'BEGIN {OFS = \"\\t\"} {print $1, $2, length($3)}' > wordslen.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "E agora podemos realizar os cálculos no Octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "octave"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.291158 bits por palavra\n",
      "2.282233 bits por caractere\n"
     ]
    }
   ],
   "source": [
    "X = load('wordslen.counts');\n",
    "c = X(:,2); l = X(:,3);\n",
    "p = c./sum(c);\n",
    "El = sum(p.*l);\n",
    "H = entropy(p);\n",
    "printf('%f bits por palavra\\n%f bits por caractere\\n',H,H/El);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "octave"
   },
   "source": [
    "Vamos comprimir o arquivo texto original utilizando a codificação Lempel-Ziv (LZ77) e verificar o tamanho do arquivo gerado (em bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663733\n"
     ]
    }
   ],
   "source": [
    "gzip -c /tmp/ulysses.txt > /tmp/ulysses.gz && ls -la /tmp/ulysses.gz | awk '{print $5}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "kernel": "octave"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gzip antigiu 3.347130 bits por caractere\n",
      "gzip antigiu 3.347130 bits por caractere\n"
     ]
    }
   ],
   "source": [
    "gz = 8*663733/1586393;\n",
    "printf('gzip antigiu %f bits por caractere',gz);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "octave",
     "octave",
     "octave",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.19.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
